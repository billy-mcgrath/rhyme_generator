{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Rhyming Couplets using The Dartmouth\n",
    "This project explores a few different ways that we can create rhyming couplets using sentences from articles appearing daily in The Dartmouth. The first sentences of the couplets are real sentences that appeared in articles that day (or the preceding few days). The second sentences are generated by the computer using different techniques including POS tagging and bigram dictionaries. Doing it this way does not always produce perfect couplets, but keeping the first lines real often preserves a sense of the news. Also by offering up a few different ways to generate couplets, it offers viewers an insight into the generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import random\n",
    "import json, ast\n",
    "import nltk\n",
    "import time\n",
    "import re\n",
    "import pronouncing\n",
    "from nltk import tokenize\n",
    "from nltk import pos_tag\n",
    "from rhyme import rhymes_with\n",
    "from nltk.corpus import cmudict\n",
    "from nltk import corpus\n",
    "from nltk import FreqDist\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble\n",
    "Some text for while the user waits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These rhyming couplets are not always good.\n",
      "But in the end, I did the best that I could.\n",
      "\n",
      "Each day, I read The Dartmouth news.\n",
      "And finds some sentences that I can use.\n",
      "\n",
      "I analyze grammar and rhyming, too.\n",
      "And generates phrases all brand-new.\n",
      "\n",
      "They call me the Couplet Generating Robot.\n",
      "The first sentences are real, the seconds are not.\n",
      "\n",
      "Right now I am training, but soon you will see.\n",
      "All of the rhymes that I have for thee...\n"
     ]
    }
   ],
   "source": [
    "print \"\"\"These rhyming couplets are not always good.\n",
    "But in the end, I did the best that I could.\n",
    "\n",
    "Each day, I read The Dartmouth news.\n",
    "And finds some sentences that I can use.\n",
    "\n",
    "I analyze grammar and rhyming, too.\n",
    "And generates phrases all brand-new.\n",
    "\n",
    "They call me the Couplet Generating Robot.\n",
    "The first sentences are real, the seconds are not.\n",
    "\n",
    "Right now I am training, but soon you will see.\n",
    "All of the rhymes that I have for thee...\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headline Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def headline_scrape(section):\n",
    "    url = \"http://www.thedartmouth.com/section/\" + section\n",
    "    r = urllib.urlopen(url).read()\n",
    "    soup = BeautifulSoup(r,\"html.parser\")\n",
    "    headlines = [j for j in soup.findAll(\"h4\", {\"class\":\"art-left-headline no-marg\"})]\n",
    "\n",
    "    for headline in headlines:\n",
    "        for a in headline.find_all('a', href=True):\n",
    "            unistring = a['href']\n",
    "            front_page.append(unistring.encode(\"utf-8\"))\n",
    "\n",
    "            title_unistring = a.text\n",
    "            page_name.append(title_unistring.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_page = []\n",
    "page_name = []\n",
    "\n",
    "sections = [\"news\", \"arts\", \"sports\", \"opinion\", \"mirror\"]\n",
    "\n",
    "for section in sections:\n",
    "    headline_scrape(section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses the urls to get the article texts for each headline and stores them in a dictionary\n",
    "article_dict = {}\n",
    "\n",
    "length = len(front_page)\n",
    "\n",
    "for i in range(0, length):\n",
    "    url = front_page[i]\n",
    "    r = urllib.urlopen(url).read()\n",
    "    soup = BeautifulSoup(r,\"html.parser\")\n",
    "\n",
    "    article = soup.find(\"div\", {\"class\":\"col-md-8 article-pg\"})\n",
    "    paras = article.find_all(\"p\", {\"class\":None})\n",
    "\n",
    "    article_text = \"\"\n",
    "    for para in paras:\n",
    "        article_text += para.text + \" \"\n",
    "\n",
    "    article_text = article_text.strip()\n",
    "    article_text = re.sub(u\"\\\".*?\\\" \", \"\", article_text)\n",
    "    \n",
    "    article_dict[page_name[i]] = article_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Syllable Counter\n",
    "https://stackoverflow.com/questions/5876040/number-of-syllables-for-words-in-a-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = cmudict.dict()\n",
    "def nsyl(word):\n",
    "    if word.lower() in d:\n",
    "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]]\n",
    "    else:\n",
    "        return [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "bigram_dict = {}\n",
    "for j in range(0, length):\n",
    "    article = article_dict[page_name[j]]\n",
    "    article_clean = re.sub(r'([^\\s\\w]|_)+', \"\", article)\n",
    "    \n",
    "    article_words = article_clean.split()\n",
    "    \n",
    "    article_bigrams = list(ngrams(article_words, 2))\n",
    "\n",
    "    for i in article_bigrams:\n",
    "        if i[0] not in bigram_dict:\n",
    "            bigram_dict[i[0]] = []\n",
    "        bigram_dict[i[0]].append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in bigram_dict:\n",
    "    if bigram_dict[key] is None:\n",
    "        del bigram_dict[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Syllable Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_syll(sent):\n",
    "    words = sent.split()\n",
    "    \n",
    "    syll = 0\n",
    "    \n",
    "    for word in words:\n",
    "        w = re.sub(r'([^\\s\\w]|_)+', \"\", word)\n",
    "        s = nsyl(w)[0]\n",
    "        if s != 0:\n",
    "            syll += s\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    return syll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below gets all sentences under 15 syllables and stores them in a list. 15 was chosen arbitrarily because I thought it would be easier from a coherence and run-time efficiency standpoint to work with shorter sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = \"\"\n",
    "for a in article_dict:\n",
    "    all_articles += article_dict[a]\n",
    "    \n",
    "art_sents = tokenize.sent_tokenize(all_articles)\n",
    "\n",
    "shorts = []\n",
    "\n",
    "for i in art_sents:\n",
    "    if sent_syll(i) <= 15 and sent_syll(i) is not None:\n",
    "        shorts.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_build():\n",
    "    sent = random.choice(shorts)\n",
    "    sent_clean = re.sub(r'([^\\s\\w]|_)+', \"\", sent)\n",
    "    \n",
    "    tag = pos_tag(tokenize.word_tokenize(sent_clean))\n",
    "    \n",
    "    gram = []\n",
    "    for i in tag:\n",
    "        gram.append(i[1])\n",
    "        \n",
    "    print sent\n",
    "    return gram\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = {}\n",
    "for k in range(0, length):\n",
    "    article = article_dict[page_name[k]]\n",
    "    \n",
    "    article_clean = re.sub(u\"(\\u2018|\\u2019|\\u201c)\", \"\", article)\n",
    "    \n",
    "    tokenized_article = tokenize.word_tokenize(article_clean)\n",
    "    \n",
    "    pos_tags = pos_tag(tokenized_article)\n",
    "    \n",
    "    for p in pos_tags:\n",
    "        if p[1] not in pos_dict:\n",
    "            pos_dict[p[1]] = []\n",
    "        if len(p[0]) > 1 and '.' not in p[0]:\n",
    "            pos_dict[p[1]].append(p[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word to POS Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_pos = {}\n",
    "for k in range(0, length):\n",
    "    article = article_dict[page_name[k]]\n",
    "    \n",
    "    article_clean = re.sub(u\"(\\u2018|\\u2019|\\u201c)\", \"\", article)\n",
    "    \n",
    "    tokenized_article = tokenize.word_tokenize(article_clean)\n",
    "    \n",
    "    pos_tags = pos_tag(tokenized_article)\n",
    "    \n",
    "    for p in pos_tags:\n",
    "        if p[0] not in word_to_pos:\n",
    "            word_to_pos[p[0]] = []\n",
    "        if len(p[1]) > 1 and '.' not in p[1]:\n",
    "            word_to_pos[p[0]].append(p[1])\n",
    "            \n",
    "for w in word_to_pos:\n",
    "    if word_to_pos[w] is None:\n",
    "        del word_to_pos[w]\n",
    "    else:\n",
    "        word_to_pos[w] = list(set(word_to_pos[w]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VB', 'VBP', 'VBN', 'NN']"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word_to_pos[\"run\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Couplet Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns a sentence and its part of speech tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_gram(num):\n",
    "    sent = shorts[num]\n",
    "    sent_clean = re.sub(r'([^\\s\\w]|_)+', \"\", sent)\n",
    "    \n",
    "    tag = pos_tag(tokenize.word_tokenize(sent_clean))\n",
    "    \n",
    "    gram = []\n",
    "    for i in tag:\n",
    "        gram.append(i[1])\n",
    "        \n",
    "    return (sent, gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets the frequency distribution of all the words in the Brown corpora for help with rhyming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown = FreqDist(corpus.brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates a couplet. The first line is a sentence chosen from the shorts list (list with all the shortish sentences from the day's articles). The second line is a randomly generated line based on the grammar and syllable length of the first sentence and then a rhyming word at the end of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def couplet(num):\n",
    "    sent = sent_gram(num)[0]\n",
    "    gram = sent_gram(num)[1]\n",
    "\n",
    "    words = re.sub(r'([^\\s\\w]|_)+', \"\", sent).split()\n",
    "    rhymes = rhymes_with(words[-1])\n",
    "    rhyme = \"\"\n",
    "    for r in rhymes:\n",
    "        if brown[r] > 0 and words[-1] not in r:\n",
    "            rhyme = r\n",
    "            \n",
    "    if rhyme == \"\":\n",
    "        return None\n",
    "            \n",
    "    new_sent = \"\"\n",
    "    tries = 0\n",
    "    while sent_syll(new_sent) != sent_syll(sent) and tries <= 100:\n",
    "        new_sent = \"\"\n",
    "        for s in gram[0:-1]:\n",
    "            new_sent += random.choice(pos_dict[s]) + \" \"\n",
    "        new_sent += rhyme\n",
    "        tries += 1\n",
    "    \n",
    "    print sent\n",
    "    print new_sent + sent[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is not, however, how it is.\n",
      "him is there especially how she whiz.\n"
     ]
    }
   ],
   "source": [
    "#couplet(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will sometimes come out pretty bizarre but it tries to build a couplet using rhyming, part of speech tagging, and bigrams!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_line(sentence):\n",
    "    sent_clean = re.sub(r'([^\\s\\w]|_)+', \"\", sentence)\n",
    "    tag = pos_tag(tokenize.word_tokenize(sent_clean))[0:-1]\n",
    "    \n",
    "    gram = []\n",
    "    for i in tag:\n",
    "        gram.append(i[1])\n",
    "    \n",
    "    prev = random.choice(pos_dict[gram[0]])\n",
    "    line = prev + \" \"\n",
    "    \n",
    "    for g in gram[1:]:\n",
    "        if prev in bigram_dict:\n",
    "            for word in bigram_dict[prev]:\n",
    "                if word in word_to_pos and g in word_to_pos[word]:\n",
    "                    line += word + \" \"\n",
    "                    break\n",
    "        else:\n",
    "            random.choice(pos_dict[g])\n",
    "    \n",
    "    rhyme_word = sent_clean.split()[-1]\n",
    "    rhymes = rhymes_with(rhyme_word)\n",
    "    \n",
    "    rhyme = \"\"\n",
    "    for r in rhymes:\n",
    "        if brown[r] > 0:\n",
    "            rhyme = r\n",
    "            \n",
    "    if rhyme == \"\":\n",
    "        return None\n",
    "    \n",
    "    print sentence\n",
    "    print line + rhyme + \".\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code compiles all of the article into one string and then breaks them up by sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = \"\"\n",
    "for a in article_dict:\n",
    "    all_articles += article_dict[a]\n",
    "    \n",
    "art_sents = tokenize.sent_tokenize(all_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This couplet takes in a sentence from the shorts list and then finds a rhyming word somewhere in any of the articles and builds the second line by the word's position. The second line is the same amount of words as the first line (except when its word placement in the sentence is earlier than the length of the first sentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rhyme(sentence):\n",
    "    cleaner = re.sub(r'([^\\s\\w]|_)+', \"\", sentence)\n",
    "    \n",
    "    word_sent = cleaner.split()\n",
    "    sent_length = len(word_sent)\n",
    "    \n",
    "    rhymes = rhymes_with(word_sent[-1])\n",
    "\n",
    "    rhyme_sent = \"\"\n",
    "    where = 10000\n",
    "    for sent in art_sents:\n",
    "        for r in rhymes:\n",
    "            finder = \" \" + r + \" \"\n",
    "            val = sent.find(finder)\n",
    "            \n",
    "            if finder in sent and val < where:\n",
    "                s = sent.split()\n",
    "                ind = s.index(r)\n",
    "                dist = 0\n",
    "                if ind - sent_length > 0:\n",
    "                    dist = ind - sent_length + 1\n",
    "                rhyme_sent = s[dist:ind+1]\n",
    "                \n",
    "    if rhyme_sent == \"\":\n",
    "        return None\n",
    "\n",
    "    print sentence\n",
    "    print \" \".join(rhyme_sent) + sentence[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is not, however, how it is.\n",
      "a foul and made both of his.\n"
     ]
    }
   ],
   "source": [
    "#find_rhyme(shorts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together!\n",
    "Here is an infinite loop that continuously prints out couplets using three styles of generation. Some come out well, some don't. But rhyming is fun, so enjoy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after three missed calls, my father finally dials me back.\n",
      "of two discovered beliefs its history so is he wrack.\n",
      "\n",
      "\n",
      "oprah intended to empower marginalized voices.\n",
      "multiple critical innovations and bold choices.\n",
      "\n",
      "\n",
      "we also had our first few upsets of the season!\n",
      "it i was your i i helps because a treason.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "flesch wields her power well.\n",
      "synagogues in pittsburgh, i tell.\n",
      "\n",
      "\n",
      "my chest burns with the fire of terror.\n",
      "their finest properties service error.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "what is the line and how strict should it be?\n",
      "on oct. 27. your legacy will live on in the?\n",
      "\n",
      "\n",
      "never again can we pray without fear.\n",
      "as early we i though year.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i’m vegan, but i’m not allergic to any foods.\n",
      "this piece of sports memorabilia also includes.\n",
      "\n",
      "\n",
      "we all just feed off each other really well.\n",
      "we all never spent all spent never yell.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "it can be a very fine line.\n",
      "could occur in a community like mine.\n",
      "\n",
      "\n",
      "through understanding comes compassion.\n",
      "in voting shanges ration.\n",
      "\n",
      "\n",
      "what do you hope your students take away from your class?\n",
      "who think it train their pundits start here in their surpass?\n",
      "\n",
      "\n",
      "we feed the animosity that spurs heinous crimes like these.\n",
      "multiple former nfl players suffered from a football-induced brain disease.\n",
      "\n",
      "\n",
      "through understanding comes compassion.\n",
      "in voting shanges ration.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "memories of the bonfire contort into destruction.\n",
      "lives in the in suction.\n",
      "\n",
      "\n",
      "no.\n",
      "woe.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "this, in essence, is confirmation bias at work.\n",
      "the past training dartmouth new training past smirk.\n",
      "\n",
      "\n",
      "unfortunately, that was the case for me on friday night.\n",
      "respectively this said the sunlight in you with dartmouth write.\n",
      "\n",
      "\n",
      "in trying times, it is easy to place blame.\n",
      "people across the country who now know your name.\n",
      "\n",
      "\n",
      "this is what keeps the mystery alive.\n",
      "the dartmouth dartmouth no training thrive.\n",
      "\n",
      "\n",
      "this is my opinion, which is based on the truth.\n",
      "the is our day that appears ranked on an youth.\n",
      "\n",
      "\n",
      "we got last year under our belt.\n",
      "the theater feeling better than i felt.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "no shared truth.\n",
      "the been youth.\n",
      "\n",
      "\n",
      "this was reflected in the character’s clothing, she said.\n",
      "every second, my dread.\n",
      "\n",
      "\n",
      "we have time to correct it and we’ll watch video on it.\n",
      "him become become to most he or adrift most become as writ.\n",
      "\n",
      "\n",
      "the shooting is in allegheny county; i start to sweat.\n",
      "the tackling says like total francisco local bring to yet.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "flesch wields her power well.\n",
      "saturday i phnom yell.\n",
      "\n",
      "\n",
      "but now is a time we must to come together.\n",
      "but soon is the crimson they would to move whether.\n",
      "\n",
      "\n",
      "“a lot of students knew about it.\n",
      "is most fond of those who submit.\n",
      "\n",
      "\n",
      "“the play was difficult material,” carter said.\n",
      "both use leonard armstrong use use widespread.\n",
      "\n",
      "\n",
      "we feed the animosity that spurs heinous crimes like these.\n",
      "we derek the milestone which is different dukes of unease.\n",
      "\n",
      "\n",
      "we have time to correct it and we’ll watch video on it.\n",
      "control over her daughters, adora is most fond of those who submit.\n",
      "\n",
      "\n",
      "it always does between us and them.\n",
      "it i takes because he or stem.\n",
      "\n",
      "\n",
      "this is my opinion, which is based on the truth.\n",
      "the is her film which informs made during this youth.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "minutes pass like years.\n",
      "redfords character years'.\n",
      "\n",
      "\n",
      "in trying times, it is easy to place blame.\n",
      "with judging goals it is able to sing tame.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "leaving the dining hall, i call my father in a panic.\n",
      "feeling the that the volcanic.\n",
      "\n",
      "\n",
      "my chest burns with the fire of terror.\n",
      "their most shows of the study of error.\n",
      "\n",
      "\n",
      "“i had never done a play before,” carter said.\n",
      "every second, my dread.\n",
      "\n",
      "\n",
      "immediately, he goes to find chloe.\n",
      "well dartmouth continue snowy.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "“i hope that it’s fun for people to listen to,” barrett said.\n",
      "every second, my dread.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "they saw the light and converted themselves.”.\n",
      "he voted the closet and was yourselves.\n",
      "\n",
      "\n",
      "flesch wields her power well.\n",
      "synagogues in pittsburgh, i tell.\n",
      "\n",
      "\n",
      "this is what keeps the mystery alive.\n",
      "the dartmouth dartmouth no training thrive.\n",
      "\n",
      "\n",
      "on day one at yale, the team won three of its six matches.\n",
      "with cutaway three while movie each mystery bloated two of her two thatches.\n",
      "\n",
      "\n",
      "we’re all white.\n",
      "knowing your light.\n",
      "\n",
      "\n",
      "they saw the light and converted themselves.”.\n",
      "he said either didnt and said yourselves.\n",
      "\n",
      "\n",
      "on day one at yale, the team won three of its six matches.\n",
      "for gopher one in energy the homecoming approached 21 out his 2012 thatches.\n",
      "\n",
      "\n",
      "probably not.\n",
      "the first shot.\n",
      "\n",
      "\n",
      "rick dove’s story is introduced for just that purpose.\n",
      "due multipurpose.\n",
      "\n",
      "\n",
      "but now is a time we must to come together.\n",
      "and about seeks the league he can to be whether.\n",
      "\n",
      "\n",
      "the shooting is in allegheny county; i start to sweat.\n",
      "last year, including in the 400m medley relay that set.\n",
      "\n",
      "\n",
      "we got last year under our belt.\n",
      "it was i doesnt because your svelte.\n",
      "\n",
      "\n",
      "i always liked new england, so i applied and moved up here.\n",
      "opening up found third tape far strong lifted and done out year.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i think i am.\n",
      "dont know hours swam.\n",
      "\n",
      "\n",
      "i always liked new england, so i applied and moved up here.\n",
      "shange alone received long lsu-bama brilliantly 6-5-5 changed and allowed up year.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "“we want to bring new life to the historic downtown,” he said.\n",
      "me feel to feel im feel to this im feel he widespread.\n",
      "\n",
      "\n",
      "this is my opinion, which is based on the truth.\n",
      "the is their country which is ashamed of the youth.\n",
      "\n",
      "\n",
      "he also looks impressively good for his age.\n",
      "suburbia of frankenmuth, michigan to the international stage.\n",
      "\n",
      "\n",
      "you had such a long life.\n",
      "they were didnt wife.\n",
      "\n",
      "\n",
      "memories of the bonfire contort into destruction.\n",
      "communities from that interest saturday whether suction.\n",
      "\n",
      "\n",
      "we’re all white.\n",
      "knowing your light.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "were you expecting such a high scoring game?\n",
      "was it clucking all the few varsity tame?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "what games are you most looking forward to this year?\n",
      "what i do you i the we're.\n",
      "\n",
      "\n",
      "this is my opinion, which is based on the truth.\n",
      "this is her ve that laurie played without the youth.\n",
      "\n",
      "\n",
      "harvard scored on five of its seven power plays last night.\n",
      "rest in peace knowing your light.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "as for the future, ortiz is uncertain but excited.\n",
      "for of this evening junction seeks able and unrequited.\n",
      "\n",
      "\n",
      "we got last year under our belt.\n",
      "the theater feeling better than i felt.\n",
      "\n",
      "\n",
      "never again can we pray without fear.\n",
      "now that i that year.\n",
      "\n",
      "\n",
      "curtis plays this role well and without exaggeration.\n",
      "lecturer provides the park again and for vocation.\n",
      "\n",
      "\n",
      "as for the future, ortiz is uncertain but excited.\n",
      "of life congregation forever altered synagogues in the united.\n",
      "\n",
      "\n",
      "i really do.\n",
      "nothing zoo.\n",
      "\n",
      "\n",
      "i understood her point.\n",
      "eerily thought us joint.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "saturday afternoon was a different story.\n",
      "only place offered the loose tempore.\n",
      "\n",
      "\n",
      "it is not, however, how it is.\n",
      "it is also also where he whiz.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "though many hate to admit it, frustration evokes response.\n",
      "for public planning i he public ways renaissance.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "through understanding comes compassion.\n",
      "band’s lack of passion.\n",
      "\n",
      "\n",
      "to my relative rose: i wish i knew you better.\n",
      "to their begin dartmouth do do begin dartmouth it sweater.\n",
      "\n",
      "\n",
      "leaving the dining hall, i call my father in a panic.\n",
      "rowing the moving clutch game am his truth as the volcanic.\n",
      "\n",
      "\n",
      "“i had never done a play before,” carter said.\n",
      "every second, my dread.\n",
      "\n",
      "\n",
      "memories of the bonfire contort into destruction.\n",
      "claudines schoolgirl schoolgirl suction.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "no.\n",
      "know.\n",
      "\n",
      "\n",
      "we’re all white.\n",
      "said that write.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i’m vegan, but i’m not allergic to any foods.\n",
      "chloe sayers but that that obtrudes.\n",
      "\n",
      "\n",
      "i read on.\n",
      "lead think wan.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "what games are you most looking forward to this year?\n",
      "who plays arent herself first we're.\n",
      "\n",
      "\n",
      "“it was busy,” he said.\n",
      "you said san it widespread.\n",
      "\n",
      "\n",
      "do i require a special diet?\n",
      "his part perfectly, letting his quiet?\n",
      "\n",
      "\n",
      "“we want to bring new life to the historic downtown,” he said.\n",
      "it doesnt to doesnt i doesnt to a i doesnt he widespread.\n",
      "\n",
      "\n",
      "“we want to bring new life to the historic downtown,” he said.\n",
      "me am to find black team to the green ridicule he widespread.\n",
      "\n",
      "\n",
      "it always does between us and them.\n",
      "for this community of which i am.\n",
      "\n",
      "\n",
      "this, in essence, is confirmation bias at work.\n",
      "the past training dartmouth new training past smirk.\n",
      "\n",
      "\n",
      "probably not.\n",
      "finally yacht.\n",
      "\n",
      "\n",
      "what are your goals for the team this season?\n",
      "kentucky, most people thought there was a good reason?\n",
      "\n",
      "\n",
      "minutes pass like years.\n",
      "men head as years'.\n",
      "\n",
      "\n",
      "we’ll get better as the year goes on with every game.\n",
      "not know super of the time aims of of every tame.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "as for the future, ortiz is uncertain but excited.\n",
      "of life congregation forever altered synagogues in the united.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "they are two different things.\n",
      "us are 2018 dominant wrings.\n",
      "\n",
      "\n",
      "in trying times, it is easy to place blame.\n",
      "people across the country who now know your name.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "desperately, i ask him if our family is safe.\n",
      "easily discordant love themselves with his laurie thinks strafe.\n",
      "\n",
      "\n",
      "we have time to correct it and we’ll watch video on it.\n",
      "control over her daughters, adora is most fond of those who submit.\n",
      "\n",
      "\n",
      "this is my opinion, which is based on the truth.\n",
      "the dartmouth training dartmouth proposed past no youth.\n",
      "\n",
      "\n",
      "gun violence in america is an epidemic.\n",
      "presence level of psychology is neither systemic.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "to my relative rose: i wish i knew you better.\n",
      "to your hate were top open trent gave myself sweater.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "the desire to be right is the thirst for truth.\n",
      "the training open new dartmouth no training past youth.\n",
      "\n",
      "\n",
      "we also had our first few upsets of the season!\n",
      "you only pulled his tear few ancestors of the treason!\n",
      "\n",
      "\n",
      "were you expecting such a high scoring game?\n",
      "across the country who now know your name?\n",
      "\n",
      "\n",
      "harvard scored on five of its seven power plays last night.\n",
      "also given whether 34 whether 34 something looks added write.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "he lives, and someday will likely die, for free solo climbing.\n",
      "the interactions between the characters and ferrell’s scarily accurate comic timing.\n",
      "\n",
      "\n",
      "we feed the animosity that spurs heinous crimes like these.\n",
      "themselves this under unease.\n",
      "\n",
      "\n",
      "minutes pass like years.\n",
      "members are of year's.\n",
      "\n",
      "\n",
      "“it was busy,” he said.\n",
      "every second, my dread.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-426-a196942aff82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfind_rhyme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msecond_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    couplet(random.randint(0, len(shorts)-1))\n",
    "    sleep(3)\n",
    "    print \"\\n\"\n",
    "    find_rhyme(random.choice(shorts))\n",
    "    sleep(3)\n",
    "    print \"\\n\"\n",
    "    second_line(random.choice(shorts))\n",
    "    sleep(3)\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
